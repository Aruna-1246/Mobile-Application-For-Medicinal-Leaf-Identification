{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6a08101",
   "metadata": {},
   "source": [
    "## MOBILENET ARCHITECTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69df34dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7239e0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\SPIRO\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2.15.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Conv2D, Conv3D, DepthwiseConv2D, SeparableConv2D, Conv3DTranspose\n",
    "from keras.layers import Flatten, MaxPool2D, AvgPool2D, GlobalAvgPool2D, UpSampling2D, BatchNormalization\n",
    "from keras.layers import Concatenate, Add, Dropout, ReLU, Lambda, Activation, LeakyReLU, PReLU\n",
    "\n",
    "\n",
    "\n",
    "from time import time\n",
    "import numpy as np\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f92c584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3462 images belonging to 36 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train=ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True,validation_split = 0.2)\n",
    "train_data=train.flow_from_directory(directory = 'DATASET/TRAIN',target_size=(224,224),\n",
    "                                     batch_size=32,class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "355dd2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 791 images belonging to 36 classes.\n"
     ]
    }
   ],
   "source": [
    "test=ImageDataGenerator(rescale=1./255)\n",
    "test_data=test.flow_from_directory(directory = 'DATASET/TEST',target_size=(224,224),\n",
    "                                   batch_size=32,class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4002a538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\SPIRO\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:277: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\SPIRO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\SPIRO\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 112, 112, 32)      896       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 112, 112, 32)      128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 112, 112, 32)      0         \n",
      "                                                                 \n",
      " depthwise_conv2d (Depthwis  (None, 112, 112, 32)      320       \n",
      " eConv2D)                                                        \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 112, 112, 32)      128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 112, 112, 32)      0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 112, 112, 64)      2112      \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 112, 112, 64)      256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " depthwise_conv2d_1 (Depthw  (None, 56, 56, 64)        640       \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 56, 56, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_3 (ReLU)              (None, 56, 56, 64)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 56, 56, 128)       8320      \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 56, 56, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_4 (ReLU)              (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " depthwise_conv2d_2 (Depthw  (None, 56, 56, 128)       1280      \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 56, 56, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_5 (ReLU)              (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 56, 56, 128)       16512     \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 56, 56, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_6 (ReLU)              (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " depthwise_conv2d_3 (Depthw  (None, 28, 28, 128)       1280      \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 28, 28, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_7 (ReLU)              (None, 28, 28, 128)       0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 28, 28, 256)       33024     \n",
      "                                                                 \n",
      " batch_normalization_8 (Bat  (None, 28, 28, 256)       1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_8 (ReLU)              (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " depthwise_conv2d_4 (Depthw  (None, 28, 28, 256)       2560      \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_9 (Bat  (None, 28, 28, 256)       1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_9 (ReLU)              (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 28, 28, 256)       65792     \n",
      "                                                                 \n",
      " batch_normalization_10 (Ba  (None, 28, 28, 256)       1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_10 (ReLU)             (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " depthwise_conv2d_5 (Depthw  (None, 14, 14, 256)       2560      \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_11 (Ba  (None, 14, 14, 256)       1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_11 (ReLU)             (None, 14, 14, 256)       0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 14, 14, 512)       131584    \n",
      "                                                                 \n",
      " batch_normalization_12 (Ba  (None, 14, 14, 512)       2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_12 (ReLU)             (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " depthwise_conv2d_6 (Depthw  (None, 14, 14, 512)       5120      \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_13 (Ba  (None, 14, 14, 512)       2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_13 (ReLU)             (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 14, 14, 512)       262656    \n",
      "                                                                 \n",
      " batch_normalization_14 (Ba  (None, 14, 14, 512)       2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " re_lu_14 (ReLU)             (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " depthwise_conv2d_7 (Depthw  (None, 14, 14, 512)       5120      \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_15 (Ba  (None, 14, 14, 512)       2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_15 (ReLU)             (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 14, 14, 512)       262656    \n",
      "                                                                 \n",
      " batch_normalization_16 (Ba  (None, 14, 14, 512)       2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_16 (ReLU)             (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " depthwise_conv2d_8 (Depthw  (None, 14, 14, 512)       5120      \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_17 (Ba  (None, 14, 14, 512)       2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_17 (ReLU)             (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 14, 14, 512)       262656    \n",
      "                                                                 \n",
      " batch_normalization_18 (Ba  (None, 14, 14, 512)       2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_18 (ReLU)             (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " depthwise_conv2d_9 (Depthw  (None, 14, 14, 512)       5120      \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_19 (Ba  (None, 14, 14, 512)       2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_19 (ReLU)             (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 14, 14, 512)       262656    \n",
      "                                                                 \n",
      " batch_normalization_20 (Ba  (None, 14, 14, 512)       2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_20 (ReLU)             (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " depthwise_conv2d_10 (Depth  (None, 14, 14, 512)       5120      \n",
      " wiseConv2D)                                                     \n",
      "                                                                 \n",
      " batch_normalization_21 (Ba  (None, 14, 14, 512)       2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_21 (ReLU)             (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 14, 14, 512)       262656    \n",
      "                                                                 \n",
      " batch_normalization_22 (Ba  (None, 14, 14, 512)       2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_22 (ReLU)             (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " depthwise_conv2d_11 (Depth  (None, 7, 7, 512)         5120      \n",
      " wiseConv2D)                                                     \n",
      "                                                                 \n",
      " batch_normalization_23 (Ba  (None, 7, 7, 512)         2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_23 (ReLU)             (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 7, 7, 1024)        525312    \n",
      "                                                                 \n",
      " batch_normalization_24 (Ba  (None, 7, 7, 1024)        4096      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_24 (ReLU)             (None, 7, 7, 1024)        0         \n",
      "                                                                 \n",
      " depthwise_conv2d_12 (Depth  (None, 7, 7, 1024)        10240     \n",
      " wiseConv2D)                                                     \n",
      "                                                                 \n",
      " batch_normalization_25 (Ba  (None, 7, 7, 1024)        4096      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_25 (ReLU)             (None, 7, 7, 1024)        0         \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 7, 7, 1024)        1049600   \n",
      "                                                                 \n",
      " batch_normalization_26 (Ba  (None, 7, 7, 1024)        4096      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_26 (ReLU)             (None, 7, 7, 1024)        0         \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 1024)              0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 36)                36900     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3276708 (12.50 MB)\n",
      "Trainable params: 3254820 (12.42 MB)\n",
      "Non-trainable params: 21888 (85.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def mobilenet(input_shape, n_classes):\n",
    "  \n",
    "  def mobilenet_block(x, f, s=1):\n",
    "    x = DepthwiseConv2D(3, strides=s, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    x = Conv2D(f, 1, strides=1, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    return x\n",
    "    \n",
    "    \n",
    "  input = Input(input_shape)\n",
    "\n",
    "  x = Conv2D(32, 3, strides=2, padding='same')(input)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = ReLU()(x)\n",
    "\n",
    "  x = mobilenet_block(x, 64)\n",
    "  x = mobilenet_block(x, 128, 2)\n",
    "  x = mobilenet_block(x, 128)\n",
    "\n",
    "  x = mobilenet_block(x, 256, 2)\n",
    "  x = mobilenet_block(x, 256)\n",
    "\n",
    "  x = mobilenet_block(x, 512, 2)\n",
    "  for _ in range(5):\n",
    "    x = mobilenet_block(x, 512)\n",
    "\n",
    "  x = mobilenet_block(x, 1024, 2)\n",
    "  x = mobilenet_block(x, 1024)\n",
    "  \n",
    "  x = GlobalAvgPool2D()(x)\n",
    "  \n",
    "  output = Dense(n_classes, activation='softmax')(x)\n",
    "  \n",
    "  model = Model(input, output)\n",
    "  model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy',tensorflow.keras.metrics.Precision()])\n",
    "  return model\n",
    "     \n",
    "\n",
    "input_shape = 224, 224, 3\n",
    "n_classes = 36\n",
    "\n",
    "K.clear_session()\n",
    "model = mobilenet(input_shape, n_classes)\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef429a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"MOBILENET.h5\"\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "M = ModelCheckpoint(model_path, monitor='accuracy', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47ff4436",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 70\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0c46be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\SPIRO\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\SPIRO\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "54/54 [==============================] - ETA: 0s - loss: 3.5062 - accuracy: 0.0856 - precision: 0.3191\n",
      "Epoch 1: accuracy improved from -inf to 0.08565, saving model to MOBILENET.h5\n",
      "54/54 [==============================] - 254s 4s/step - loss: 3.5062 - accuracy: 0.0856 - precision: 0.3191\n",
      "Epoch 2/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 3.0506 - accuracy: 0.1516 - precision: 0.4400\n",
      "Epoch 2: accuracy improved from 0.08565 to 0.15162, saving model to MOBILENET.h5\n",
      "54/54 [==============================] - 227s 4s/step - loss: 3.0506 - accuracy: 0.1516 - precision: 0.4400\n",
      "Epoch 3/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 2.7738 - accuracy: 0.2118 - precision: 0.5030\n",
      "Epoch 3: accuracy improved from 0.15162 to 0.21181, saving model to MOBILENET.h5\n",
      "54/54 [==============================] - 223s 4s/step - loss: 2.7738 - accuracy: 0.2118 - precision: 0.5030\n",
      "Epoch 4/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 2.5450 - accuracy: 0.2791 - precision: 0.5750\n",
      "Epoch 4: accuracy improved from 0.21181 to 0.27908, saving model to MOBILENET.h5\n",
      "54/54 [==============================] - 217s 4s/step - loss: 2.5450 - accuracy: 0.2791 - precision: 0.5750\n",
      "Epoch 5/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 2.3167 - accuracy: 0.3310 - precision: 0.6279\n",
      "Epoch 5: accuracy improved from 0.27908 to 0.33102, saving model to MOBILENET.h5\n",
      "54/54 [==============================] - 225s 4s/step - loss: 2.3167 - accuracy: 0.3310 - precision: 0.6279\n",
      "Epoch 6/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 2.0998 - accuracy: 0.3987 - precision: 0.6894\n",
      "Epoch 6: accuracy improved from 0.33102 to 0.39873, saving model to MOBILENET.h5\n",
      "54/54 [==============================] - 226s 4s/step - loss: 2.0998 - accuracy: 0.3987 - precision: 0.6894\n",
      "Epoch 7/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 1.9191 - accuracy: 0.4334 - precision: 0.6919\n",
      "Epoch 7: accuracy improved from 0.39873 to 0.43345, saving model to MOBILENET.h5\n",
      "54/54 [==============================] - 304s 6s/step - loss: 1.9191 - accuracy: 0.4334 - precision: 0.6919\n",
      "Epoch 8/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 1.8764 - accuracy: 0.4301 - precision: 0.6523\n",
      "Epoch 8: accuracy did not improve from 0.43345\n",
      "54/54 [==============================] - 269s 5s/step - loss: 1.8764 - accuracy: 0.4301 - precision: 0.6523\n",
      "Epoch 9/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 1.7318 - accuracy: 0.4797 - precision: 0.6858\n",
      "Epoch 9: accuracy improved from 0.43345 to 0.47975, saving model to MOBILENET.h5\n",
      "54/54 [==============================] - 261s 5s/step - loss: 1.7318 - accuracy: 0.4797 - precision: 0.6858\n",
      "Epoch 10/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 1.5077 - accuracy: 0.5388 - precision: 0.7384\n",
      "Epoch 10: accuracy improved from 0.47975 to 0.53877, saving model to MOBILENET.h5\n",
      "54/54 [==============================] - 253s 5s/step - loss: 1.5077 - accuracy: 0.5388 - precision: 0.7384\n",
      "Epoch 11/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 1.4094 - accuracy: 0.5637 - precision: 0.7399\n",
      "Epoch 11: accuracy improved from 0.53877 to 0.56366, saving model to MOBILENET.h5\n",
      "54/54 [==============================] - 228s 4s/step - loss: 1.4094 - accuracy: 0.5637 - precision: 0.7399\n",
      "Epoch 12/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 1.3813 - accuracy: 0.5781 - precision: 0.7479\n",
      "Epoch 12: accuracy improved from 0.56366 to 0.57812, saving model to MOBILENET.h5\n",
      "54/54 [==============================] - 229s 4s/step - loss: 1.3813 - accuracy: 0.5781 - precision: 0.7479\n",
      "Epoch 13/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 1.3525 - accuracy: 0.5734 - precision: 0.7487\n",
      "Epoch 13: accuracy did not improve from 0.57812\n",
      "54/54 [==============================] - 221s 4s/step - loss: 1.3525 - accuracy: 0.5734 - precision: 0.7487\n",
      "Epoch 14/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 1.2581 - accuracy: 0.6157 - precision: 0.7744\n",
      "Epoch 14: accuracy improved from 0.57812 to 0.61574, saving model to MOBILENET.h5\n",
      "54/54 [==============================] - 225s 4s/step - loss: 1.2581 - accuracy: 0.6157 - precision: 0.7744\n",
      "Epoch 15/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 1.1868 - accuracy: 0.6269 - precision: 0.7765\n",
      "Epoch 15: accuracy improved from 0.61574 to 0.62691, saving model to MOBILENET.h5\n",
      "54/54 [==============================] - 219s 4s/step - loss: 1.1868 - accuracy: 0.6269 - precision: 0.7765\n",
      "Epoch 16/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 1.1330 - accuracy: 0.6475 - precision: 0.7958\n",
      "Epoch 16: accuracy improved from 0.62691 to 0.64747, saving model to MOBILENET.h5\n",
      "54/54 [==============================] - 245s 5s/step - loss: 1.1330 - accuracy: 0.6475 - precision: 0.7958\n",
      "Epoch 17/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 1.1307 - accuracy: 0.6375 - precision: 0.7872\n",
      "Epoch 17: accuracy did not improve from 0.64747\n",
      "54/54 [==============================] - 274s 5s/step - loss: 1.1307 - accuracy: 0.6375 - precision: 0.7872\n",
      "Epoch 18/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.9611 - accuracy: 0.6973 - precision: 0.8116\n",
      "Epoch 18: accuracy improved from 0.64747 to 0.69734, saving model to MOBILENET.h5\n",
      "54/54 [==============================] - 287s 5s/step - loss: 0.9611 - accuracy: 0.6973 - precision: 0.8116\n",
      "Epoch 19/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.9354 - accuracy: 0.6881 - precision: 0.8172\n",
      "Epoch 19: accuracy did not improve from 0.69734\n",
      "54/54 [==============================] - 227s 4s/step - loss: 0.9354 - accuracy: 0.6881 - precision: 0.8172\n",
      "Epoch 20/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.9247 - accuracy: 0.7027 - precision: 0.8084\n",
      "Epoch 20: accuracy improved from 0.69734 to 0.70270, saving model to MOBILENET.h5\n",
      "54/54 [==============================] - 262s 5s/step - loss: 0.9247 - accuracy: 0.7027 - precision: 0.8084\n",
      "Epoch 21/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.8492 - accuracy: 0.7396 - precision: 0.8505\n",
      "Epoch 21: accuracy improved from 0.70270 to 0.73958, saving model to MOBILENET.h5\n",
      "54/54 [==============================] - 242s 4s/step - loss: 0.8492 - accuracy: 0.7396 - precision: 0.8505\n",
      "Epoch 22/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.8400 - accuracy: 0.7391 - precision: 0.8297\n",
      "Epoch 22: accuracy did not improve from 0.73958\n",
      "54/54 [==============================] - 364s 7s/step - loss: 0.8400 - accuracy: 0.7391 - precision: 0.8297\n",
      "Epoch 23/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.8490 - accuracy: 0.7419 - precision: 0.8305\n",
      "Epoch 23: accuracy improved from 0.73958 to 0.74190, saving model to MOBILENET.h5\n",
      "54/54 [==============================] - 269s 5s/step - loss: 0.8490 - accuracy: 0.7419 - precision: 0.8305\n",
      "Epoch 24/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.6963 - accuracy: 0.7708 - precision: 0.8550\n",
      "Epoch 24: accuracy improved from 0.74190 to 0.77083, saving model to MOBILENET.h5\n",
      "54/54 [==============================] - 224s 4s/step - loss: 0.6963 - accuracy: 0.7708 - precision: 0.8550\n",
      "Epoch 25/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.7259 - accuracy: 0.7743 - precision: 0.8576\n",
      "Epoch 25: accuracy improved from 0.77083 to 0.77431, saving model to MOBILENET.h5\n",
      "54/54 [==============================] - 259s 5s/step - loss: 0.7259 - accuracy: 0.7743 - precision: 0.8576\n",
      "Epoch 26/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.6712 - accuracy: 0.7807 - precision: 0.8644\n",
      "Epoch 26: accuracy improved from 0.77431 to 0.78067, saving model to MOBILENET.h5\n",
      "54/54 [==============================] - 261s 5s/step - loss: 0.6712 - accuracy: 0.7807 - precision: 0.8644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.6305 - accuracy: 0.7899 - precision: 0.8661\n",
      "Epoch 27: accuracy improved from 0.78067 to 0.78993, saving model to MOBILENET.h5\n",
      "54/54 [==============================] - 224s 4s/step - loss: 0.6305 - accuracy: 0.7899 - precision: 0.8661\n",
      "Epoch 28/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.6168 - accuracy: 0.8067 - precision: 0.8658\n",
      "Epoch 28: accuracy improved from 0.78993 to 0.80671, saving model to MOBILENET.h5\n",
      "54/54 [==============================] - 232s 4s/step - loss: 0.6168 - accuracy: 0.8067 - precision: 0.8658\n",
      "Epoch 29/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.5708 - accuracy: 0.8171 - precision: 0.8759\n",
      "Epoch 29: accuracy improved from 0.80671 to 0.81713, saving model to MOBILENET.h5\n",
      "54/54 [==============================] - 234s 4s/step - loss: 0.5708 - accuracy: 0.8171 - precision: 0.8759\n",
      "Epoch 30/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.5916 - accuracy: 0.8020 - precision: 0.8577\n",
      "Epoch 30: accuracy did not improve from 0.81713\n",
      "54/54 [==============================] - 222s 4s/step - loss: 0.5916 - accuracy: 0.8020 - precision: 0.8577\n",
      "Epoch 31/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.6105 - accuracy: 0.7975 - precision: 0.8586\n",
      "Epoch 31: accuracy did not improve from 0.81713\n",
      "54/54 [==============================] - 222s 4s/step - loss: 0.6105 - accuracy: 0.7975 - precision: 0.8586\n",
      "Epoch 32/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.5158 - accuracy: 0.8258 - precision: 0.8844\n",
      "Epoch 32: accuracy improved from 0.81713 to 0.82581, saving model to MOBILENET.h5\n",
      "54/54 [==============================] - 224s 4s/step - loss: 0.5158 - accuracy: 0.8258 - precision: 0.8844\n",
      "Epoch 33/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.4893 - accuracy: 0.8449 - precision: 0.8927\n",
      "Epoch 33: accuracy improved from 0.82581 to 0.84491, saving model to MOBILENET.h5\n",
      "54/54 [==============================] - 220s 4s/step - loss: 0.4893 - accuracy: 0.8449 - precision: 0.8927\n",
      "Epoch 34/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.4923 - accuracy: 0.8384 - precision: 0.8896\n",
      "Epoch 34: accuracy did not improve from 0.84491\n",
      "54/54 [==============================] - 214s 4s/step - loss: 0.4923 - accuracy: 0.8384 - precision: 0.8896\n",
      "Epoch 35/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.4175 - accuracy: 0.8553 - precision: 0.9069\n",
      "Epoch 35: accuracy improved from 0.84491 to 0.85532, saving model to MOBILENET.h5\n",
      "54/54 [==============================] - 225s 4s/step - loss: 0.4175 - accuracy: 0.8553 - precision: 0.9069\n",
      "Epoch 36/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.4579 - accuracy: 0.8531 - precision: 0.8929\n",
      "Epoch 36: accuracy did not improve from 0.85532\n",
      "54/54 [==============================] - 223s 4s/step - loss: 0.4579 - accuracy: 0.8531 - precision: 0.8929\n",
      "Epoch 37/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.5765 - accuracy: 0.8108 - precision: 0.8668\n",
      "Epoch 37: accuracy did not improve from 0.85532\n",
      "54/54 [==============================] - 215s 4s/step - loss: 0.5765 - accuracy: 0.8108 - precision: 0.8668\n",
      "Epoch 38/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.5061 - accuracy: 0.8396 - precision: 0.8797\n",
      "Epoch 38: accuracy did not improve from 0.85532\n",
      "54/54 [==============================] - 220s 4s/step - loss: 0.5061 - accuracy: 0.8396 - precision: 0.8797\n",
      "Epoch 39/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.5395 - accuracy: 0.8190 - precision: 0.8670\n",
      "Epoch 39: accuracy did not improve from 0.85532\n",
      "54/54 [==============================] - 215s 4s/step - loss: 0.5395 - accuracy: 0.8190 - precision: 0.8670\n",
      "Epoch 40/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.4359 - accuracy: 0.8536 - precision: 0.8962\n",
      "Epoch 40: accuracy did not improve from 0.85532\n",
      "54/54 [==============================] - 224s 4s/step - loss: 0.4359 - accuracy: 0.8536 - precision: 0.8962\n",
      "Epoch 41/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.3686 - accuracy: 0.8831 - precision: 0.9252\n",
      "Epoch 41: accuracy improved from 0.85532 to 0.88310, saving model to MOBILENET.h5\n",
      "54/54 [==============================] - 220s 4s/step - loss: 0.3686 - accuracy: 0.8831 - precision: 0.9252\n",
      "Epoch 42/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.4129 - accuracy: 0.8666 - precision: 0.9052\n",
      "Epoch 42: accuracy did not improve from 0.88310\n",
      "54/54 [==============================] - 222s 4s/step - loss: 0.4129 - accuracy: 0.8666 - precision: 0.9052\n",
      "Epoch 43/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.3951 - accuracy: 0.8744 - precision: 0.9138\n",
      "Epoch 43: accuracy did not improve from 0.88310\n",
      "54/54 [==============================] - 223s 4s/step - loss: 0.3951 - accuracy: 0.8744 - precision: 0.9138\n",
      "Epoch 44/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.3603 - accuracy: 0.8778 - precision: 0.9158\n",
      "Epoch 44: accuracy did not improve from 0.88310\n",
      "54/54 [==============================] - 219s 4s/step - loss: 0.3603 - accuracy: 0.8778 - precision: 0.9158\n",
      "Epoch 45/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.4600 - accuracy: 0.8559 - precision: 0.9034\n",
      "Epoch 45: accuracy did not improve from 0.88310\n",
      "54/54 [==============================] - 219s 4s/step - loss: 0.4600 - accuracy: 0.8559 - precision: 0.9034\n",
      "Epoch 46/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.3299 - accuracy: 0.8912 - precision: 0.9161\n",
      "Epoch 46: accuracy improved from 0.88310 to 0.89120, saving model to MOBILENET.h5\n",
      "54/54 [==============================] - 220s 4s/step - loss: 0.3299 - accuracy: 0.8912 - precision: 0.9161\n",
      "Epoch 47/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.3131 - accuracy: 0.9013 - precision: 0.9255\n",
      "Epoch 47: accuracy improved from 0.89120 to 0.90129, saving model to MOBILENET.h5\n",
      "54/54 [==============================] - 226s 4s/step - loss: 0.3131 - accuracy: 0.9013 - precision: 0.9255\n",
      "Epoch 48/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.3446 - accuracy: 0.8906 - precision: 0.9231\n",
      "Epoch 48: accuracy did not improve from 0.90129\n",
      "54/54 [==============================] - 215s 4s/step - loss: 0.3446 - accuracy: 0.8906 - precision: 0.9231\n",
      "Epoch 49/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.3078 - accuracy: 0.8964 - precision: 0.9227\n",
      "Epoch 49: accuracy did not improve from 0.90129\n",
      "54/54 [==============================] - 221s 4s/step - loss: 0.3078 - accuracy: 0.8964 - precision: 0.9227\n",
      "Epoch 50/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.3076 - accuracy: 0.8935 - precision: 0.9189\n",
      "Epoch 50: accuracy did not improve from 0.90129\n",
      "54/54 [==============================] - 217s 4s/step - loss: 0.3076 - accuracy: 0.8935 - precision: 0.9189\n",
      "Epoch 51/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.2834 - accuracy: 0.9042 - precision: 0.9281\n",
      "Epoch 51: accuracy improved from 0.90129 to 0.90423, saving model to MOBILENET.h5\n",
      "54/54 [==============================] - 223s 4s/step - loss: 0.2834 - accuracy: 0.9042 - precision: 0.9281\n",
      "Epoch 52/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.3409 - accuracy: 0.8802 - precision: 0.9072\n",
      "Epoch 52: accuracy did not improve from 0.90423\n",
      "54/54 [==============================] - 224s 4s/step - loss: 0.3409 - accuracy: 0.8802 - precision: 0.9072\n",
      "Epoch 53/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.2875 - accuracy: 0.9160 - precision: 0.9339\n",
      "Epoch 53: accuracy improved from 0.90423 to 0.91598, saving model to MOBILENET.h5\n",
      "54/54 [==============================] - 235s 4s/step - loss: 0.2875 - accuracy: 0.9160 - precision: 0.9339\n",
      "Epoch 54/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.3102 - accuracy: 0.8948 - precision: 0.9238\n",
      "Epoch 54: accuracy did not improve from 0.91598\n",
      "54/54 [==============================] - 225s 4s/step - loss: 0.3102 - accuracy: 0.8948 - precision: 0.9238\n",
      "Epoch 55/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.2809 - accuracy: 0.9089 - precision: 0.9322\n",
      "Epoch 55: accuracy did not improve from 0.91598\n",
      "54/54 [==============================] - 222s 4s/step - loss: 0.2809 - accuracy: 0.9089 - precision: 0.9322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.2984 - accuracy: 0.9062 - precision: 0.9217\n",
      "Epoch 56: accuracy did not improve from 0.91598\n",
      "54/54 [==============================] - 223s 4s/step - loss: 0.2984 - accuracy: 0.9062 - precision: 0.9217\n",
      "Epoch 57/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.2414 - accuracy: 0.9195 - precision: 0.9395\n",
      "Epoch 57: accuracy improved from 0.91598 to 0.91951, saving model to MOBILENET.h5\n",
      "54/54 [==============================] - 219s 4s/step - loss: 0.2414 - accuracy: 0.9195 - precision: 0.9395\n",
      "Epoch 58/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.2620 - accuracy: 0.9101 - precision: 0.9339\n",
      "Epoch 58: accuracy did not improve from 0.91951\n",
      "54/54 [==============================] - 222s 4s/step - loss: 0.2620 - accuracy: 0.9101 - precision: 0.9339\n",
      "Epoch 59/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.2047 - accuracy: 0.9317 - precision: 0.9507\n",
      "Epoch 59: accuracy improved from 0.91951 to 0.93171, saving model to MOBILENET.h5\n",
      "54/54 [==============================] - 226s 4s/step - loss: 0.2047 - accuracy: 0.9317 - precision: 0.9507\n",
      "Epoch 60/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.1652 - accuracy: 0.9427 - precision: 0.9539\n",
      "Epoch 60: accuracy improved from 0.93171 to 0.94271, saving model to MOBILENET.h5\n",
      "54/54 [==============================] - 227s 4s/step - loss: 0.1652 - accuracy: 0.9427 - precision: 0.9539\n",
      "Epoch 61/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.1953 - accuracy: 0.9377 - precision: 0.9483\n",
      "Epoch 61: accuracy did not improve from 0.94271\n",
      "54/54 [==============================] - 217s 4s/step - loss: 0.1953 - accuracy: 0.9377 - precision: 0.9483\n",
      "Epoch 62/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.2565 - accuracy: 0.9248 - precision: 0.9415\n",
      "Epoch 62: accuracy did not improve from 0.94271\n",
      "54/54 [==============================] - 215s 4s/step - loss: 0.2565 - accuracy: 0.9248 - precision: 0.9415\n",
      "Epoch 63/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.2564 - accuracy: 0.9195 - precision: 0.9380\n",
      "Epoch 63: accuracy did not improve from 0.94271\n",
      "54/54 [==============================] - 222s 4s/step - loss: 0.2564 - accuracy: 0.9195 - precision: 0.9380\n",
      "Epoch 64/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.2485 - accuracy: 0.9207 - precision: 0.9363\n",
      "Epoch 64: accuracy did not improve from 0.94271\n",
      "54/54 [==============================] - 214s 4s/step - loss: 0.2485 - accuracy: 0.9207 - precision: 0.9363\n",
      "Epoch 65/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.2129 - accuracy: 0.9300 - precision: 0.9465\n",
      "Epoch 65: accuracy did not improve from 0.94271\n",
      "54/54 [==============================] - 220s 4s/step - loss: 0.2129 - accuracy: 0.9300 - precision: 0.9465\n",
      "Epoch 66/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.2303 - accuracy: 0.9242 - precision: 0.9439\n",
      "Epoch 66: accuracy did not improve from 0.94271\n",
      "54/54 [==============================] - 219s 4s/step - loss: 0.2303 - accuracy: 0.9242 - precision: 0.9439\n",
      "Epoch 67/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.1995 - accuracy: 0.9306 - precision: 0.9431  \n",
      "Epoch 67: accuracy did not improve from 0.94271\n",
      "54/54 [==============================] - 4330s 82s/step - loss: 0.1995 - accuracy: 0.9306 - precision: 0.9431\n",
      "Epoch 68/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.2018 - accuracy: 0.9282 - precision: 0.9423\n",
      "Epoch 68: accuracy did not improve from 0.94271\n",
      "54/54 [==============================] - 222s 4s/step - loss: 0.2018 - accuracy: 0.9282 - precision: 0.9423\n",
      "Epoch 69/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.1792 - accuracy: 0.9410 - precision: 0.9557\n",
      "Epoch 69: accuracy did not improve from 0.94271\n",
      "54/54 [==============================] - 220s 4s/step - loss: 0.1792 - accuracy: 0.9410 - precision: 0.9557\n",
      "Epoch 70/100\n",
      "52/54 [===========================>..] - ETA: 7s - loss: 0.1698 - accuracy: 0.9451 - precision: 0.9598 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#### Fitting the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m      3\u001b[0m            train_data, steps_per_epoch\u001b[38;5;241m=\u001b[39mtrain_data\u001b[38;5;241m.\u001b[39msamples \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m batch_size, \n\u001b[0;32m      4\u001b[0m            epochs\u001b[38;5;241m=\u001b[39mepochs, \n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#            validation_data=test_data,validation_steps=test_data.samples // batch_size,\u001b[39;00m\n\u001b[0;32m      6\u001b[0m            callbacks\u001b[38;5;241m=\u001b[39m[M])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1805\u001b[0m ):\n\u001b[0;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    869\u001b[0m       args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_config\n\u001b[0;32m    870\u001b[0m   )\n\u001b[0;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[0;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1325\u001b[0m     args,\n\u001b[0;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1327\u001b[0m     executing_eagerly)\n\u001b[0;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1487\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1488\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1489\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1490\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1491\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1492\u001b[0m   )\n\u001b[0;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1501\u001b[0m   )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#### Fitting the model\n",
    "history = model.fit(\n",
    "           train_data, steps_per_epoch=train_data.samples // batch_size, \n",
    "           epochs=epochs, \n",
    "#            validation_data=test_data,validation_steps=test_data.samples // batch_size,\n",
    "           callbacks=[M])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020a8c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8039ca93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.plot(history.history['accuracy'])\n",
    "\n",
    "for i in range(epochs):\n",
    "    if i%5 == 0:\n",
    "        plt.annotate(np.round(history.history['accuracy'][i]*100,2),xy=(i,history.history['accuracy'][i]))\n",
    "\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f76ca6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "plt.plot(history.history['loss'])\n",
    "\n",
    "for i in range(epochs):\n",
    "    if i%5 == 0:\n",
    "        plt.annotate(np.round(history.history['loss'][i]*100,2),xy=(i,history.history['loss'][i]))\n",
    "\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e9807f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108b2bf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eba4e20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36d81c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
